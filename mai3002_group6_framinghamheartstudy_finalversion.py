# -*- coding: utf-8 -*-
"""MAI3002_Group6_FraminghamHeartStudy_FinalVersion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5-5_bFKX7q8qsb_zMXzSBm7KCPYCL52

<a href="https://colab.research.google.com/github/JrrJrrJrr/MAI3002_Framingham/blob/main/GroupProject_MAI3002_Group6.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# **MAI3002 - Group 6**
Cleo Habets - i6337758

Jerrica Pubben - i6276134

Noura al Sayed - i6359287

# **Introduction**

## **Research questions**

Research question:

'Can changes in pulse pressure between Visit 1 and Visit 2 predict the occurrence of a CVD event before Visit 3 in Framingham participants?'

Subquestion:

1. Is the association between ΔPP and CVD different for women vs men?

# **Data preparation**

## **0. Libraries, config, load data**
"""

# ------------------------------------------------------------
# Installation helper
# ------------------------------------------------------------
import sys, subprocess # Accesses Python system functions.

req_url = "https://raw.githubusercontent.com/JrrJrrJrr/MAI3002_Framingham/main/requirements.txt"

try:
    import google.colab
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", req_url]) # Runs shell commands from Python.
except ImportError:
    print("Local environment: run manually if needed:")
    print(f"pip install -r {req_url}")

# ------------------------------------------------------------
# Imports
# ------------------------------------------------------------

import numpy as np                                                      # Efficient numerical computations and arrays.
import pandas as pd                                                     # Data loading, cleaning, and manipulation using DataFrames.
import matplotlib.pyplot as plt                                         # Core plotting library for static figures.
import seaborn as sns                                                   # High-level statistical visualizations built on matplotlib.

from matplotlib.colors import LinearSegmentedColormap                   # Custom color gradients for plots.
from sklearn.impute import SimpleImputer                                # Replaces missing values using strategies like mean or median.

import ipywidgets as widgets                                            # Creates interactive controls (sliders, dropdowns).
from ipywidgets import interact                                         # Quickly links widgets to functions.
from ipywidgets import fixed                                            # Fixes function arguments when using widgets.
from IPython.display import display                                     # Displays widgets and outputs in notebooks.

from sklearn.model_selection import (
    train_test_split,                                                   # Splits data into training and test sets.
    StratifiedKFold,                                                    # Cross-validation preserving class proportions.
    GridSearchCV,                                                       # Hyperparameter tuning using cross-validation.
    cross_val_score                                                     # Evaluates model performance via cross-validation.
)
from sklearn.pipeline import Pipeline                                   # Chains preprocessing and modeling steps.
from sklearn.preprocessing import StandardScaler, FunctionTransformer   # Standardizes features (mean 0, variance 1).
from sklearn.metrics import (
    accuracy_score,                                                     # Overall classification accuracy.
    classification_report,                                              # Precision, recall, and F1-score summary.
    roc_auc_score,                                                      # Measures model discrimination ability.
    roc_curve,                                                          # ROC curve data points.
    confusion_matrix,                                                   # Counts true/false positives and negatives.
    ConfusionMatrixDisplay                                              # Visualizes the confusion matrix.
)

# Pipeline & SMOTE from imblearn
from imblearn.pipeline import Pipeline as ImbPipeline                   # Pipeline that supports resampling steps.
from imblearn.over_sampling import SMOTE                                # Oversamples minority class using synthetic samples.

# Models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.dummy import DummyClassifier                               # Baseline model for comparison.
from sklearn.base import (
    BaseEstimator,
    ClassifierMixin                                                     # Build custom sklearn-compatible models.
)
from sklearn.compose import ColumnTransformer                           # Applies different preprocessing to different columns.
from sklearn.impute import SimpleImputer
from sklearn.utils.class_weight import compute_class_weight             # Computes class weights to compensate for class imbalance by assigning higher importance to underrepresented classes
from tensorflow import keras                                            # Neural network framework for deep learning models.

# Load dataset (Long format; multiple rows per RANDID)

cvd = pd.read_csv('https://raw.githubusercontent.com/LUCE-Blockchain/Databases-for-teaching/refs/heads/main/Framingham%20Dataset.csv')

print("Raw data shape:", cvd.shape) # Rows, columns
cvd.head()

"""# **Data exploration**

## **Data structure**
"""

# Column names, NN count, data type

cvd.info()

# Numeric summary

cvd.describe().T

"""# **1. Helper functions**
-> Central place so we donn't redefine things all over

## **Continuous crest colormap for sns**
"""

# Crest colormap for sns (Consistent visual style)
crest_colors = sns.color_palette("viridis", as_cmap=False)
crest_cmap = LinearSegmentedColormap.from_list("crest_cmap", crest_colors, N=256)

"""## Missing % per column, stratified by group_col"""

def missing_by_group(df, group_col="PERIOD", columns=None, round_to=1):
    """Return % missing per column, stratified by group_col."""
    if columns is None:
        columns = df.columns.tolist()
    columns = [c for c in columns if c in df.columns]

    miss = (
        df.groupby(group_col)[columns] # Splits data into period 1, 2, 3
        .apply(lambda d: d.isna().mean() * 100)
        .round(round_to)
    )
    return miss

"""## Missing by group (heatmap)"""

def plot_missing_by_group(
        miss_by_group,
        group_col="PERIOD",
        cmap=crest_cmap,
        figsize=(10, 6),
        annotate=True # Telling we want to add labels to this
):
    """Heatmap of missingness by group (e.g. PERIOD)."""
    data = miss_by_group.T
    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(
        data,
        annot=annotate,
        fmt=".1f",
        cmap=cmap,
        cbar_kws={"label": "% Missing"},
        ax=ax,
    )
    ax.set_title(f"Missingness by {group_col}", fontsize=13, pad=8)
    ax.set_xlabel(group_col)
    ax.set_ylabel("Variable")
    fig.tight_layout()
    plt.show()
    return fig, ax

"""## Numeric distribution (histograms)"""

def plot_numeric_distributions(
    df,
    cols,
    bins=25,
    kde=True, # Kernel Density Estimate > smooth, curved line
    palette="viridis",
    figsize=(12, 6),
    ncols=4,
    stratify_by=None,
    suptitle="Distributions of Numeric Variables",
):
    """Grid of histograms (optionally stratified)."""
    n = len(cols)
    nrows = int(np.ceil(n / ncols)) # Rounds up to the next whole number
    fig, axes = plt.subplots(
        nrows=nrows, ncols=ncols, figsize=figsize, constrained_layout=True
    )
    # Only if one plot, treated like list instead of object and flattens the grid.
    axes = np.atleast_1d(axes).ravel()

    for i, col in enumerate(cols): # Loops through columns (i = index)
        ax = axes[i]
        if stratify_by and stratify_by in df.columns: # Checks splitting in groups
            sns.histplot(
                data=df,
                x=col,
                hue=stratify_by,
                bins=bins,
                kde=kde,
                element="step",
                common_norm=False, # Normalize each group independently
                palette=palette,
                ax=ax,
            )
            ax.set_title(f"{col} by {stratify_by}", fontsize=11)
        else:
            sns.histplot(
                data=df,
                x=col,
                bins=bins,
                kde=kde,
                color=sns.color_palette(palette)[-1],
                edgecolor="black",
                ax=ax,
            )
            ax.set_title(col, fontsize=11)
        ax.set_xlabel("")
        ax.set_ylabel("Count")

    # Hide unused subplots if grid is larger than #cols
    for j in range(i + 1, len(axes)):
        axes[j].axis("off")

    fig.suptitle(suptitle, fontsize=14, y=1.02)
    plt.show()
    return fig, axes

"""## Categorical distributions (countplots)"""

def plot_categorical_distributions(
    df,
    cols,
    palette="viridis",
    figsize=(12, 6),
    ncols=4,
    stratify_by=None,
    suptitle="Categorical Distributions",
    rotate_x=25, # So long words do not overlap
    show_values=False,
):
    """Grid of countplots (optionally stratified by another variable)."""
    n = len(cols)
    nrows = int(np.ceil(n / ncols))
    fig, axes = plt.subplots(
        nrows=nrows, ncols=ncols, figsize=figsize, constrained_layout=True
    )
    axes = np.atleast_1d(axes).ravel()

    for i, col in enumerate(cols):
        ax = axes[i]
        # Prevents the code from trying to split a column by itself
        use_hue = stratify_by and (stratify_by in df.columns) and (stratify_by != col)
        hue_col = stratify_by if use_hue else None

        sns.countplot(
            data=df,
            x=col,
            hue=hue_col,
            palette=palette,
            ax=ax,
        )

        ax.set_title(
            # Colum name as title, subgroup label if hue variable exists
            f"{col}" + (f" by {hue_col}" if hue_col else ""),
            fontsize=11,
        )
        ax.set_xlabel("")
        ax.set_ylabel("Count")
        ax.tick_params(axis="x", rotation=rotate_x)

        if hue_col:
            if i == 0:
                ax.legend(
                    title=hue_col,
                    frameon=False,
                    fontsize=8,
                    title_fontsize=9,
                    loc="upper right",
                )
            else:
                ax.get_legend().remove()
        else:
            leg = ax.get_legend()
            if leg:
                leg.remove()

        if show_values:
            for container in ax.containers: # Holds all bar objects in the plot
                ax.bar_label(container, fmt="%d", padding=2, fontsize=8)

    for j in range(i + 1, len(axes)):
        axes[j].axis("off")

    fig.suptitle(suptitle, fontsize=14, y=1.02)
    plt.show()
    return fig, axes

"""## IQR-based outlier summary per variable"""

def detect_outliers_iqr(df, columns=None, multiplier=1.5, sort=True, show_top=None):
    """IQR-based outlier summary per variable."""
    if columns is None:
        columns = df.select_dtypes(include=np.number).columns.tolist()


    summary = {}
    # Infinite values > NaNs
    for col in columns:
        s = df[col].replace([np.inf, -np.inf], np.nan).dropna()
        if s.nunique() <= 1:
            continue

        Q1, Q3 = s.quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower, upper = Q1 - multiplier * IQR, Q3 + multiplier * IQR
        n_outliers = ((s < lower) | (s > upper)).sum()
        pct_outliers = round(n_outliers / len(s) * 100, 2)

        summary[col] = {
            "Q1": Q1,
            "Q3": Q3,
            "IQR": IQR,
            "Lower_bound": lower,
            "Upper_bound": upper,
            "Outlier_count": n_outliers,
            "Percent_outliers": pct_outliers,
            "Valid_N": int(len(s)),
        }

    outlier_df = pd.DataFrame(summary).T
    if sort and not outlier_df.empty:
        outlier_df = outlier_df.sort_values("Percent_outliers", ascending=False)

    display(outlier_df.head(show_top) if show_top else outlier_df)
    return outlier_df

"""## Boxplots (IQR whiskers)"""

def plot_boxplots_iqr(
    df,
    columns,
    multiplier=1.5,
    ncols=4,
    figsize_row=3.0,
    palette="viridis",
    dashed_guides=True,
    suptitle="Outlier Inspection — Boxplots (IQR whiskers)",
):
    """Boxplots for a set of columns with optional IQR guide lines."""
    n = len(columns)
    nrows = int(np.ceil(n / ncols))
    fig, axes = plt.subplots(
        nrows=nrows,
        ncols=ncols,
        figsize=(4 * ncols, figsize_row * nrows),
        constrained_layout=True, # Prevents overlapping
    )
    axes = np.atleast_1d(axes).ravel()

    color = sns.color_palette(palette)[-1]
    edgecolor = "0.25"

    for i, col in enumerate(columns):
        ax = axes[i]
        s = df[col].replace([np.inf, -np.inf], np.nan).dropna()
        if s.size == 0:
            ax.set_title(f"{col} (no data)")
            ax.axis("off")
            continue

        sns.boxplot(
            x=s,
            ax=ax,
            color=color,
            fliersize=2,
            linewidth=1.2,
            boxprops=dict(edgecolor=edgecolor),
            medianprops=dict(color=edgecolor),
            whiskerprops=dict(color=edgecolor),
            capprops=dict(color=edgecolor),
        )
        ax.set_title(col, fontsize=11)
        ax.set_xlabel("")

        if dashed_guides and s.nunique() > 1:
            Q1, Q3 = s.quantile([0.25, 0.75])
            IQR = Q3 - Q1
            lb = Q1 - multiplier * IQR
            ub = Q3 + multiplier * IQR
            ax.axvline(lb, ls="--", lw=1, color=edgecolor, alpha=0.7)
            ax.axvline(ub, ls="--", lw=1, color=edgecolor, alpha=0.7)

    for j in range(i + 1, len(axes)):
        axes[j].axis("off")

    fig.suptitle(suptitle, fontsize=13, y=1.02)
    plt.show()
    return fig, axes

"""## % Outliers by group (e.g. PERIOD)"""

def iqr_outlier_summary_by_group(df, columns, group_col="PERIOD", multiplier=1.5):
    """% outliers by group (e.g. PERIOD) for selected columns."""
    out = {}
    for g, sub in df.groupby(group_col):
        col_dict = {}
        for col in columns:
            if col not in sub.columns:
                continue
            s = sub[col].replace([np.inf, -np.inf], np.nan).dropna()
            if s.size <= 1:
                col_dict[col] = np.nan
                continue
            Q1, Q3 = s.quantile([0.25, 0.75])
            IQR = Q3 - Q1
            lb, ub = Q1 - multiplier * IQR, Q3 + multiplier * IQR
            pct = ((s < lb) | (s > ub)).mean() * 100
            col_dict[col] = round(pct, 1)
        out[g] = col_dict
    wide = pd.DataFrame(out).sort_index()
    return wide

"""## Heatmap of outlier % by group"""

def plot_outliers_heatmap(
    wide_table,
    cmap=crest_cmap,
    title="IQR Outliers (%) by Group",
    figsize=(14, 10)
):
    """Heatmap of outlier % by group (rows=features, cols=groups)."""
    if wide_table.empty:
        print("No data to plot.")
        return None, None
    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(
        wide_table,
        annot=True,
        fmt=".1f",
        cmap=cmap,
        cbar_kws={"label": "% Outliers"},
        ax=ax,
    )
    ax.set_title(title, fontsize=13, pad=8)
    ax.set_xlabel("Group")
    ax.set_ylabel("Feature")
    fig.tight_layout()
    plt.show()
    return fig, ax

"""## Boxplots by grouping variable (e.g. period)"""

def plot_boxplots_by_group(
    df,
    columns,
    group_col="PERIOD",
    ncols=3,
    figsize_row=3.4,
    palette="viridis",
    suptitle="Boxplots by Group",
):
    """Boxplots of each column by a grouping variable (e.g. PERIOD)."""
    n = len(columns)
    nrows = int(np.ceil(n / ncols))
    fig, axes = plt.subplots(
        nrows=nrows,
        ncols=ncols,
        figsize=(5 * ncols, figsize_row * nrows),
        constrained_layout=True,
    )
    axes = np.atleast_1d(axes).ravel()

    for i, col in enumerate(columns):
        ax = axes[i]
        if col not in df.columns or group_col not in df.columns:
            ax.set_title(f"{col} (missing)")
            ax.axis("off")
            continue

        sns.boxplot(
            data=df,
            x=group_col,
            y=col,
            palette=palette,
            ax=ax,
        )
        ax.set_title(f"{col} by {group_col}", fontsize=11)
        ax.set_xlabel(group_col)
        ax.set_ylabel(col)

    for j in range(i + 1, len(axes)):
        axes[j].axis("off")

    fig.suptitle(suptitle, fontsize=13, y=1.02)
    plt.show()
    return fig, axes

"""# **2. Longitudinal structure: periods and participants**

## **Periods**
"""

# Period distribution: rows per PERIOD (visit)

print("\nPERIOD distribution (rows):")
print(cvd['PERIOD'].value_counts().sort_index())

"""## Participants and number of visits"""

# Longitudinal nature of research:
# 1 participant can have multiple rows (max. 3)

n_participants = cvd['RANDID'].nunique()
visit_counts = cvd.groupby('RANDID')['PERIOD'].nunique()

print(f"\nUnique participants: {n_participants}")
print("\nVisits per participant (value counts):")
print(visit_counts.value_counts().sort_index())

# Visual: barplot: number of examination cycles per participant

cvd['RANDID'].value_counts().value_counts().sort_index().plot(kind='bar')
plt.title('Number of examination cycles per participant')
plt.xlabel('Visits per participant')
plt.ylabel('Number of participants')
plt.show()

"""## *Interactive participants' timelines*"""

def plot_patient_timeline(user_id):
    # Data extraction for the user
    user_data = cvd[cvd['RANDID'] == user_id].sort_values('PERIOD')

    if user_data.empty:
        print(f"No data for ID {user_id}")
        return

    # 3 graphs next to each other
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # Graph 1: Blood Pressure (both systolic and diastolic)
    axes[0].plot(user_data['PERIOD'],
                 user_data['SYSBP'],
                 marker='o', label='SYSBP',
                 color='red')
    axes[0].plot(user_data['PERIOD'],
                 user_data['DIABP'],
                 marker='o',
                 label='DIABP',
                 color='blue')
    axes[0].set_title("Blood Pressure")
    axes[0].set_ylabel("mmHg")
    axes[0].set_xlabel("Period (Visit)")
    axes[0].set_xticks([1, 2, 3])
    axes[0].legend()
    axes[0].grid(True, linestyle='--', alpha=0.5)

    # Graph 2: BMI
    axes[1].plot(user_data['PERIOD'],
                 user_data['BMI'],
                 marker='s',
                 color='green',
                 linestyle='--')
    axes[1].set_title("BMI")
    axes[1].set_ylabel("Kg/m**2")
    axes[1].set_xlabel("Period (Visit)")
    axes[1].set_xticks([1, 2, 3])
    axes[1].grid(True, linestyle='--', alpha=0.5)

    # Graph 3: Cholesterol
    axes[2].plot(user_data['PERIOD'],
                 user_data['TOTCHOL'],
                 marker='^',
                 color='orange')
    axes[2].set_title("Cholesterol")
    axes[2].set_ylabel("mg/dL")
    axes[2].set_xlabel("Periode (Visit)")
    axes[2].set_xticks([1, 2, 3])
    axes[2].grid(True, linestyle='--', alpha=0.5)

    # Title
    has_cvd = "YES" if user_data['CVD'].max() == 1 else "NO" # Check for CVD
    plt.suptitle(f"Health trajectory for patient {user_id} (Developed CVD: {has_cvd})", fontsize=16)

    plt.tight_layout()
    plt.show()

# Interactive widget
ids = sorted(cvd['RANDID'].unique())
interact(plot_patient_timeline,
                 user_id=widgets.Dropdown(options=ids, description='Chose ID:'));

"""# **3. Missing data overview and analysis**

## **Missing data overview**
"""

# Overall missingness
missing = cvd.isna().sum().sort_values(ascending=False)
missing_pct = (missing / len(cvd) * 100).round(2)
missing_summary = pd.DataFrame({'Missing values': missing, '%': missing_pct})
missing_summary[missing_summary['Missing values'] > 0]

# Visual: barplot: % missing per variable (non-zero only)

plt.figure(figsize=(10, 5))
nonzero_missing = missing_pct[missing_pct > 0]
sns.barplot(
    x=nonzero_missing,
    y=nonzero_missing.index,
    palette="viridis"
)
plt.title("Missing Values by Variable (%)")
plt.xlabel("% Missing")
plt.ylabel("")
plt.tight_layout()
plt.show()

# Missing (%) per column, stratified by PERIOD for selected variables

group_col = "PERIOD"
cols = [
    "LDLC",
    "HDLC",
    "GLUCOSE",
    "BPMEDS",
    "TOTCHOL",
    "educ",
    "CIGPDAY",
    "BMI",
    "HEARTRTE",
]

# Compute % missing by PERIOD
miss_by_period = missing_by_group(
    df=cvd, group_col=group_col, columns=cols, round_to=1
)

# Display table
display(miss_by_period)

#Plot heatmap
plot_missing_by_group(
    miss_by_period,
    group_col=group_col,
    cmap=crest_cmap,
    figsize=(8, 4),
    annotate=True,
)

"""## **Missingness interpretation (MCAR/MAR/MNAR)**

| Variable | % Missing | Interpretation |
|----------|------------|----------------|
| LDLC     | 73.97%     | MNAR (measured only in Period 3) |
| HDLC     | 73.97%     | MNAR (measured only in Period 3) |
| GLUCOSE  | 12.38%     | MAR (lab/patient-related) |
| BPMEDS   | 5.10%      | MCAR (random entry error) |
| TOTCHOL  | 3.52%      | MCAR |
| educ     | 2.54%      | MAR (sociodemographic) |
| CIGPDAY  | 0.68%      | MCAR |
| BMI      | 0.45%      | MCAR |
| HEARTRTE | 0.05%      | MCAR |

# **4. Distributions**

## **Numeric / categorical variables**
"""

# Numerical variables

num_vars = ['AGE','SYSBP','DIABP','BMI','TOTCHOL','GLUCOSE','CIGPDAY']

# Categorical variables

cat_vars = ["SEX", "CURSMOKE", "DIABETES", "BPMEDS", "PREVHYP", "CVD", "PERIOD"]

"""## **Numeric distributions**"""

# Visual: Overall numeric distributions (raw)

# Overall numeric distributions (raw)
plot_numeric_distributions(
    cvd,
    num_vars,
    kde=True,
    stratify_by=None,
    suptitle="Overall Numeric Distributions (raw)"
);

# Visual: numeric distributions - Stratified by PERIOD (raw)

plot_numeric_distributions(
    cvd,
    num_vars,
    kde=True,
    stratify_by="PERIOD",
    suptitle="Numeric Distributions by PERIOD (raw)",
);

"""## **Categorical distribution**"""

# Overall categorical distribution (raw)

plot_categorical_distributions(
    df=cvd,
    cols=cat_vars,
    stratify_by=None,
    palette="viridis",
    show_values=True,
    suptitle="Overall Categorical Distributions",
);

# Categorical distribution - Stratified by PERIOD (raw)

plot_categorical_distributions(
    df=cvd,
    cols=cat_vars,
    stratify_by="PERIOD",
    palette="viridis",
    show_values=False,
    suptitle="Categorical Distributions by PERIOD",
);

"""# **Outliers**

## **Outlier detection**
"""

# Boxplots overall (raw)

plot_boxplots_iqr(cvd, columns=num_vars, multiplier=1.5, ncols=4);

# Boxplots stratified by PERIOD (raw)

plot_boxplots_by_group(cvd, columns=num_vars, group_col='PERIOD', ncols=3);

# Outlier summary - IQR method (raw)

outlier_summary = detect_outliers_iqr(cvd, columns=num_vars)

"""## **Outlier handling**

### **Ranges (clinically motivated)**
"""

# Defining clinically motivated ranges
# I have removed AGE and CIGPDAY from the ranges below: they do not need to be capped
# All AGE values (27 - 83) are plausible

cvd_capped = cvd.copy()

ranges = {
    "SYSBP": (80, 250),     # <80 = circulatory failure; >250 = critical hypertensive crisis
    "DIABP": (40, 140),     # <40 = severy hypotension; >140 = above hypertensive crisis thresholds
    "BMI": (15, 70),        # <15 = severe anorexia; >70 = extreme obesity, likely data entry artifact
    "TOTCHOL": (75, 600),   # <75 = hypocholesterolemia (only seen in severe liver disease or malnutrition); >600 = extreme familial hypercholesterolemia (extremely rare)
    "GLUCOSE": (40, 500),   # <40 = severe hypoglycemia; >500 = hyperglycemic crisis (>600 mostly flagged as measurement error)
    "CIGPDAY": (0, 90),     # 0 = subject doesn't smoke; >90 = extremely rare (entry error/misunderstanding?)
}

"""### **Winsorising outliers**"""

# Winsorising/capping extreme values

for col, (low, high) in ranges.items():
    if col in cvd_capped.columns:
        cvd_capped[col] = cvd_capped[col].clip(lower=low, upper=high)

print("Extreme values capped within clinically defensible bounds → cvd_capped")

# Summary: how many values were capped per variable

flag_summary = []
for col, (low, high) in ranges.items():
    if col in cvd.columns:
        below_low = (cvd[col] < low).sum()
        above_high = (cvd[col] > high).sum()
        total_capped = below_low + above_high
        flag_summary.append(
            {
                "Variable": col,
                "Below lower bound": below_low,
                "Above upper bound": above_high,
                "Total capped": total_capped,
            }
        )

flag_df = pd.DataFrame(flag_summary)
display(flag_df.sort_values("Total capped", ascending=False))

plt.figure(figsize=(7, 4))
sns.barplot(data=flag_df, x="Total capped", y="Variable", palette="viridis")
plt.title("Number of Values Capped per Variable")
plt.xlabel("Count of Capped Observations")
plt.ylabel("")
plt.tight_layout()
plt.show()

# Summary: by PERIOD on capped data (Table + heatmap)

# Table
wide = iqr_outlier_summary_by_group(
    cvd_capped, columns=num_vars, group_col="PERIOD", multiplier=1.5
)
display(wide)

# Heatmap
plot_outliers_heatmap(
    wide, title="IQR Outliers (%) by PERIOD after capping", figsize=(8, 4)
);

# Summary: by PERIOD on capped data (Boxplots)

plot_boxplots_by_group(

    cvd_capped,
    columns=num_vars,
    group_col="PERIOD",
    ncols=3,
    suptitle="Boxplots by PERIOD after capping",
);

"""## **Outcome imbalance**"""

# Only select PERIOD 3

cvd_period3 = cvd_capped[cvd_capped['PERIOD'] == 3]

# Outcomes occur at visit 3 only

for outcome in ['CVD', 'STROKE', 'ANYCHD', 'HYPERTEN', 'DEATH']:
    if outcome in cvd_period3.columns:
        counts = cvd_period3[outcome].value_counts(dropna=False)
        pct_pos = (counts.get(1, 0) / len(cvd_period3) * 100).round(2)

        print(f"\n{outcome} at visit 3:")
        print(counts)
        print(f"Percent positive: {pct_pos}%")

# Visual + table: CVD Outcome distribution (PRIMARY OUTCOME)

# Countplot
sns.countplot(data=cvd_period3, x='CVD', palette='viridis')
plt.title('CVD Outcome Distribution (visit 3 Only)')
plt.xlabel('CVD (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

# Table
cvd_period3['CVD'].value_counts(normalize=True).mul(100).round(2)

"""## **Correlation and relationships**

## **Period and variable selection**
"""

# BASELINE (only PERIOD 1)
cvd_period1 = cvd_capped[cvd_capped['PERIOD'] == 1].copy()

# Relevant continuous variables
cont_vars = ['AGE','SYSBP','DIABP','BMI','TOTCHOL','GLUCOSE']

"""## **Correlation matrix**"""

# Correlation matrix on BASELINE data (only PERIOD 1)
plt.figure(figsize=(10,8))
corr = cvd_period1[cont_vars].corr()
sns.heatmap(
    corr,
    annot=True,
    cmap='vlag',
    center=0)
plt.title('Correlation Matrix of continuous variables (BASELINE period 1)')
plt.show()

# Relationship plots (scatterplot + regression line) (BASELINE only)
pairs = [
    ('AGE','SYSBP'),
    ('BMI','SYSBP'),
    ('TOTCHOL','GLUCOSE'),
    ('AGE','BMI')
]

# Colour palette to match the rest
crest_color_scatter_single = sns.color_palette("viridis")[1] # Select a single color
crest_color_reg_single = sns.color_palette("viridis")[-1] # Select a single color

for x, y in pairs:
    plt.figure(figsize=(6,4))
    sns.scatterplot(
        data=cvd_period1,
        x=x,
        y=y,
        color=crest_color_scatter_single, # Use the single color
        alpha=0.4,
        edgecolor=None)
    sns.regplot(
        data=cvd_period1,
        x=x,
        y=y,
        scatter=False,
        color=crest_color_reg_single, # Use the single color
        line_kws={'linewidth':1.5}
    )
    plt.title(f'{x} vs {y} (Baseline period 1)')
    plt.tight_layout()
    plt.show()

# Pairplot (BASELINE only)
sns.pairplot(cvd_period1[cont_vars],
             diag_kind='kde',
             corner=True,
             plot_kws=dict(color=crest_color_scatter_single, alpha=0.4),
             diag_kws=dict(color=crest_color_reg_single, linewidth=1.5)
             )
plt.suptitle('Pairwise relationships (BASELINE period 1)', y=1.02)
plt.show()

"""# **Data cleaning (EDA ONLY)**

## **1. Missingness overview on capped data**
"""

# 1. Missingness overview on capped data
missing_pct = (cvd_capped.isna().mean() * 100).round(2)
display(missing_pct[missing_pct > 0].sort_values(ascending=False))

# Make a working copy for imputation (EDA-level)
cvd_imputed = cvd_capped.copy()

"""## **Missingness analysis**

| Variable | % Missing | Interpretation |
|-----------|------------|----------------|
| LDLC | 73.97| Measured only in Period 3 → structural missingness (MNAR) |
| HDLC | 73.97| Measured only in Period 3 → structural missingness (MNAR) |
| GLUCOSE | 12.38 | Low lab missingness → patient or lab factors (MAR) |
| BPMEDS | 5.10| Almost complete → random entry error (MCAR)|
| TOTCHOL | 3.52 | Negligible missingness → lab factors? (MCAR)|
| educ | 2.54 | Minor sociodemographic missingness → nonresponsesoci (likely MAR) |
|CIGPDAY|0.68| Random nonresponse (MCAR)|
| BMI | 0.45 | Random recording or measurement (MCAR)|
|HEARTRTE| 0.05|Ignorable, almost complete|


**Interpretation:**  

**MCAR (Completely at Random)**

Data are missing by chance; imputation has minimal bias risk (e.g., BMI, TOTCHOL, BPMEDS).

**MAR (At Random)**

Missingness is related to other observed variables but not to the missing value itself (e.g., education, glucose). Median or model-based imputation is sufficient.

**MNAR (Not at Random)**
  
Missingness is due to study design or unobserved factors (HDLC, LDLC). Imputation would distort meaning; Variables should be excluded or analyzed separately (Period 3 subset).

## **2. Define columns for imputation**
"""

# 2. Define columns for imputation
num_cols = ['GLUCOSE', 'TOTCHOL', 'CIGPDAY', 'BMI', 'HEARTRTE']
cat_cols = ['BPMEDS', 'educ']

# Safety: keep only columns that actually exist (in case of prior changes)
num_cols = [c for c in num_cols if c in cvd_imputed.columns]
cat_cols = [c for c in cat_cols if c in cvd_imputed.columns]

"""## **3. Drop MNAR / design-missing variables (HDLC, LDLC are essentially Period-3 only)**"""

# 3. Drop MNAR / design-missing variables (HDLC, LDLC are essentially Period-3 only)
exclude_vars = ['HDLC', 'LDLC']
cvd_imputed = cvd_imputed.drop(columns=exclude_vars, errors='ignore')

"""## **4. Define imputers**"""

# 4. Define imputers
imp_median = SimpleImputer(strategy='median')
imp_mode   = SimpleImputer(strategy='most_frequent')

"""## **5. Apply imputers to selected columns**"""

# 5. Apply imputers to selected columns
if num_cols:
    cvd_imputed[num_cols] = imp_median.fit_transform(cvd_imputed[num_cols])

if cat_cols:
    cvd_imputed[cat_cols] = imp_mode.fit_transform(cvd_imputed[cat_cols])

print(f"Dropped MNAR variables: {exclude_vars}")
print("Remaining missing values (all columns):", int(cvd_imputed.isna().sum().sum()))

"""## **6. Remaining missingness per column**"""

# 6. Remaining missingness per column
remaining_missing = cvd_imputed.isna().mean().mul(100).round(2)
display(remaining_missing[remaining_missing > 0])

"""## **7. Distribution plots after imputation**"""

# 7. Visual: Distribution plots after imputation
plot_numeric_distributions(
    df=cvd_imputed,
    cols=['GLUCOSE', 'TOTCHOL', 'CIGPDAY', 'BMI'],
    kde=True,
    stratify_by='PERIOD',
    palette='viridis'
);

"""## **8. Recode binary variables and SEX**"""

# 8. Recode binary variables and SEX

# Identify binary columns: only {0,1} and not missing
binary_cols = [
    c for c in cvd_imputed.columns
    if set(cvd_imputed[c].dropna().unique()) <= {0, 1}
]

# Convert all binary columns to int for consistency
cvd_imputed[binary_cols] = cvd_imputed[binary_cols].astype(int)

# SEX recoding (dataset default: 1=Male, 2=Female)
if 'SEX' in cvd_imputed.columns:
    # Values not in {1, 2} will become NaN.
    cvd_imputed['SEX'] = cvd_imputed['SEX'].map({1: 0, 2: 1})

    # Handle NaNs introduced by the map operation (if any).
    # Filling with the mode is a common strategy for categorical NaNs.
    if cvd_imputed['SEX'].isnull().any():
        sex_mode = cvd_imputed['SEX'].mode()[0]
        cvd_imputed['SEX'] = cvd_imputed['SEX'].fillna(sex_mode)
        print(f"Filled {cvd_imputed['SEX'].isnull().sum()} NaNs in 'SEX' with mode ({int(sex_mode)}) after recoding.")

    # Convert to integer type.
    cvd_imputed['SEX'] = cvd_imputed['SEX'].astype(int)
    print("SEX recoded: 0 = Male, 1 = Female")
    print("\nSEX value counts after recode:")
    print(cvd_imputed['SEX'].value_counts(dropna=False))

print(f"\nBinary columns standardized: {len(binary_cols)}")

# Quick structural check
cvd_imputed.info()

"""## **9. Visuals: numeric distributions**"""

num_cols_plot = ['AGE', 'SYSBP', 'DIABP', 'BMI', 'TOTCHOL', 'GLUCOSE', 'CIGPDAY']

# 9a. Overall numeric distributions post-cleaning (whole cohort)
plot_numeric_distributions(
    df=cvd_imputed,
    cols=num_cols_plot,
    kde=True,
    stratify_by=None,
    palette='viridis'
)

# 9b. Numeric distributions by PERIOD (to see time trends)
plot_numeric_distributions(
    df=cvd_imputed,
    cols=num_cols_plot,
    kde=True,
    stratify_by='PERIOD',
    palette='viridis'
)

# Check check double check remaining missingness
cvd_imputed.isnull().sum()

"""## **Log transformation**

Data still shows skewness after imputation. Use log1p (log(x+1)) for transformation as it takes 0 into account.

CIGPDAY will not change much because of very high zero count. We can consider binning this or use binary variable (0=Non-smoker, 1=smoker).
"""

# Log1p transformation

cvd_imputed['GLUCOSE_LOG'] = np.log1p(cvd_imputed['GLUCOSE'])
cvd_imputed['CIGPDAY_LOG'] = np.log1p(cvd_imputed['CIGPDAY'])
cvd_imputed['TOTCHOL_LOG'] = np.log1p(cvd_imputed['TOTCHOL'])

# Visual: log transformed variables

plot_numeric_distributions(
    cvd_imputed,
    ['GLUCOSE_LOG', 'CIGPDAY_LOG', 'TOTCHOL_LOG'],
    kde=True
);

"""# **Feature engineering**

## **New var: pulse pressure variable**

* Represents arterial stiffness
* High (>60 mmHg) is linked to increased cvd risk (especially with increasing age)
* We will look at the difference (delta, Δ) of pulse pressure between period 1 and 2 to predict CVD in period 3


**Pulse pressure = systolic blood pressure - diastolic blood pressure**
"""

# **Feature engineering: Pulse Pressure, ΔPP, analytic dataset**
# 1. Working copy after cleaning/imputation
cvd_features = cvd_imputed.copy()

# 2. Create pulse pressure (PP = SYSBP − DIABP) for each row
cvd_features['PULSE_PRESSURE'] = cvd_features['SYSBP'] - cvd_features['DIABP']

print("Pulse pressure summary (all periods):")
print(cvd_features['PULSE_PRESSURE'].describe().round(2))

# 2a. Visual: quick PP sanity plot
sns.histplot(
    data=cvd_features,
    x='PULSE_PRESSURE',
    bins=30,
    kde=True,
    color=sns.color_palette("viridis")[3]
)
plt.title("Distribution of Pulse Pressure (all periods)")
plt.xlabel("PULSE_PRESSURE (SYSBP − DIABP)")
plt.tight_layout()
plt.show()

"""## **Wide format**"""

# 3. Build wide format: PP1, PP2, PP3 per participant
pp_wide = (
    cvd_features[['RANDID', 'PERIOD', 'PULSE_PRESSURE']]
    .dropna(subset=['PULSE_PRESSURE'])
    .drop_duplicates(['RANDID', 'PERIOD'])  # safety: 1 row per RANDID/PERIOD
    .pivot(index='RANDID', columns='PERIOD', values='PULSE_PRESSURE')
    .rename(columns={1: 'PP1', 2: 'PP2', 3: 'PP3'})
)

print("PP wide shape:", pp_wide.shape)
pp_wide.head()

"""## **Compute ΔPP = PP2 − PP1**"""

# 4. Compute ΔPP = PP2 − PP1, keep only participants with both visits
pp_delta = (
    pp_wide[['PP1', 'PP2']]
    .dropna()  # require both V1 & V2
    .assign(DELTA_PP=lambda d: d['PP2'] - d['PP1'])
    .reset_index()
)

print("Participants with PP1 & PP2:", pp_delta['RANDID'].nunique())
pp_delta[['DELTA_PP']].describe()

"""## *Interactive PP*"""

def interactive_pp(SYSBP, DIABP):
  return SYSBP - DIABP

def interactive_pp_delta(PP1, PP2):
  return PP2 - PP1

interact(interactive_pp, SYSBP= (80, 250, 0.1), DIABP= (40, 140, 0.1));

interact(interactive_pp_delta, PP1= (15, 185, 0.1), PP2= (15, 158, 0.1));

# Interactive PP for each participant/ user
def display_pulse_pressure_stats(user_id):
    # Selecting data for the user
    # Copy to avoid warnings
    user_df = cvd[cvd['RANDID'] == user_id].copy()

    if user_df.empty:
        print(f"No data found for {user_id}")
        return

    # We needed o sort by PERIOD so delta pp can be calculated
    user_df = user_df.sort_values('PERIOD')

    # Calculate Pulse Pressure (systolic bp - diastolic bp)
    user_df['PULSE_PRESSURE'] = user_df['SYSBP'] - user_df['DIABP']

    # Calculate Delta Pulse Pressure (PP2 - PP1)
    # The function diff() substracts the previous pulse pressure from the new measured one
    user_df['DELTA_PP'] = user_df['PULSE_PRESSURE'].diff()

    # Creating a table
    # We select only the relevant colums
    cols_to_show = ['RANDID', 'PERIOD', 'SYSBP', 'DIABP', 'PULSE_PRESSURE', 'DELTA_PP']

    # No decimals, + or - before the delta pulse
    styled_table = user_df[cols_to_show].style.format({
        'SYSBP': '{:.0f}',
        'DIABP': '{:.0f}',
        'PULSE_PRESSURE': '{:.0f}',
        'DELTA_PP': '{:+.0f}'  # E.g. '+5' or '-3'
    }, na_rep="-") # Measurement has no previous, so it gets a '-'

    display(styled_table)

# Haal alle unieke ID's op uit de dataset voor de keuzelijst
n_participants = sorted(cvd['RANDID'].unique())

# Maak de interactieve widget
widgets.interact(display_pulse_pressure_stats, user_id=widgets.Dropdown(options=n_participants, description='Pick ID:'));

"""## **Primary endpoint (Outcome visit 3)**"""

# 5. Outcome at visit 3: CVD (primary endpoint)
outcome_v3 = (
    cvd_features.loc[cvd_features['PERIOD'] == 3, ['RANDID', 'CVD']]
      .drop_duplicates('RANDID')
)

print("Participants with CVD outcome at visit 3:", outcome_v3['RANDID'].nunique())

"""## **Baseline covariates visit 1**"""

# 6. Baseline covariates from Visit 1
baseline_v1 = (
    cvd_features.loc[cvd_features['PERIOD'] == 1,
                     ['RANDID', 'AGE', 'SEX', 'BMI',
                      'SYSBP', 'DIABP', 'GLUCOSE', 'TOTCHOL', 'CIGPDAY']]
      .drop_duplicates('RANDID')
      .add_prefix('V1_')
      .rename(columns={'V1_RANDID': 'RANDID'})
)

print("Baseline V1 rows:", baseline_v1.shape[0])

"""## **Final analytic dataset for ML**"""

# 7. Final analytic dataset (1 row per person)
analytic = (
    pp_delta
      .merge(outcome_v3, on='RANDID', how='inner')   # require CVD outcome at Visit 3
      .merge(baseline_v1, on='RANDID', how='left')   # add baseline features
)

print("\nFINAL analytic dataset shape:", analytic.shape)
analytic.head()

"""# **Analytic dataset: overview**

Final analytic N: intersection of those with:
- Complete BP data at Visits 1 & 2 (to compute ΔPP)
- Observed CVD outcome by Visit 3


| **Study stage / Inclusion criteria**     | **Count (N)** |
| ---------------------------------------- | ------------- |
| Total participants                       | 4,434         |
| Participants with PP data at V1 & V2     | 3,930         |
| Participants with CVD data at V3         | 3,263         |
| Final analytic sample (ΔPP & V3 outcome) | 3,206         |
"""

# Class balance (analytic only)
print("CVD class counts (analytic):")
print(analytic['CVD'].value_counts())

print("\nCVD class balance (%):")
print(
    analytic['CVD']
    .value_counts(normalize=True)
    .mul(100)
    .round(2)
)

"""## *Interactive final dataset inspection: CVD groups*"""

def select_cvd_data_analytic(cvd_status, df):
  '''Filter the analytic dataframe on CVD yes/no.'''
  # Filtering
  subset = df.loc[df['CVD'] == cvd_status]
  # Extra info (nice for our report)
  print(f"--- Group: CVD = {cvd_status} ---")
  print(f"Number of patients: {len(subset)}")
  if 'V1_AGE' in subset.columns:
    print(f"Mean age: {subset['V1_AGE'].mean():.1f} years")
  return subset.head(10)

# The interactive widget
interact(select_cvd_data_analytic, cvd_status=sorted(analytic['CVD'].unique()), df=fixed(analytic));

"""## **Summary statistics and correlations**"""

# ΔPP distribution by CVD
print("\nΔPP summary (analytic):")
print(analytic['DELTA_PP'].describe().round(2))

# Visual: boxplot
sns.boxplot(data=analytic, x='CVD', y='DELTA_PP', palette='viridis')
plt.title('Change in Pulse Pressure (ΔPP) by CVD Outcome (analytic)')
plt.xlabel('CVD (0 = No, 1 = Yes)')
plt.ylabel('ΔPP (PP2 − PP1, mmHg)')
plt.tight_layout()
plt.show()

# Visual: correlation among ΔPP and key baseline variables
corr_vars = ['DELTA_PP', 'V1_AGE', 'V1_BMI', 'V1_SYSBP', 'V1_DIABP']
corr_table = analytic[corr_vars].corr().round(2)

plt.figure(figsize=(5, 4))
sns.heatmap(corr_table, annot=True, cmap=crest_cmap, center=0)
plt.title('Correlation among ΔPP and baseline variables (analytic)')
plt.tight_layout()
plt.show()

"""## *Interactive Analytic data exploration*"""

def explore_final_set(x_axis, y_axis, on_color):
  fig, ax = plt.subplots(figsize=(10, 6))

  sns.scatterplot(
      data=analytic,
      x=x_axis,
      y=y_axis,
      hue=on_color,
      alpha=0.6,
      palette='viridis',
      ax=ax
        )

  ax.set_title(f"Final Set: {x_axis} vs {y_axis} (Modifier: {on_color})", fontsize=14)
  ax.set_xlabel(x_axis, fontsize=12)
  ax.set_ylabel(y_axis, fontsize=12)
  ax.grid(True, linestyle='--', alpha=0.5)
  # So that the legenda does not go over the graph
  sns.move_legend(ax, "upper left", bbox_to_anchor=(1, 1))
  plt.tight_layout() # Everything fits
  plt.show()

# Extracting columns from the analytic df
numeric_cols = analytic.select_dtypes(include=['float64', 'int64']).columns.sort_values()
all_cols = analytic.columns.sort_values()

# The interactive widget
interact(explore_final_set,
                     x_axis=widgets.Dropdown(options=numeric_cols, value='V1_AGE', description='X-axis:'),
                     y_axis=widgets.Dropdown(options=numeric_cols, value='V1_SYSBP', description='Y-axis:'),
                     on_color=widgets.Dropdown(options=all_cols, value='CVD', description='On color:')
    );

"""## *Interactive distributions comparison*"""

def compare_distributions(variable, split_on):
    fig, ax = plt.subplots(figsize=(10, 6))

    # KDE plot (Kernel Density Estimate)
    sns.kdeplot(
        data=analytic,
        x=variable,
        hue=split_on,
        fill=True,
        common_norm=False,
        palette='viridis',
        alpha=0.4,
        ax=ax
        )

    # Titels en labels via het ax-object
    ax.set_title(f"Distribution of '{variable}' split on '{split_on}'", fontsize=14)
    ax.set_xlabel(variable, fontsize=12)
    ax.set_ylabel("Density", fontsize=12)
    ax.grid(True, linestyle='--', alpha=0.3)
    # Nice legenda
    sns.move_legend(ax, "upper right")

    plt.tight_layout()
    plt.show()

# Numeric columns for X-axis
num_cols = analytic.select_dtypes(include=['float64', 'int64']).columns.sort_values()

# Categorical columns to split (the colors)
cat_cols = ["CVD", "V1_SEX"]

# Interactieve widget
interact(compare_distributions,
                     variable=widgets.Dropdown(options=num_cols, value='V1_BMI', description='Variable:'),
                     split_on=widgets.Dropdown(options=cat_cols, value='CVD', description='Group:')
    );

"""# **Machine Learning**

# **Setup**
"""

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, FunctionTransformer
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    roc_auc_score,
    roc_curve,
    ConfusionMatrixDisplay,
    confusion_matrix,
)

#Pipeline en SMOTE from imblearn
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE

#Models
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.dummy import DummyClassifier
from sklearn.base import BaseEstimator
from sklearn.base import ClassifierMixin
from tensorflow import keras
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import FunctionTransformer

"""## **Define feature set**"""

# 1. Define feature set
feature_cols = [
    "DELTA_PP",
    "V1_AGE",
    "V1_SEX",
    "V1_BMI",
    "V1_SYSBP",
    "V1_DIABP",
    "V1_GLUCOSE",
    "V1_TOTCHOL",
    "V1_CIGPDAY",
]

"""## **Target design**"""

# 2. Design matrix X and target y
X = analytic[feature_cols].copy()
y = analytic["CVD"].copy()

print("X shape:", X.shape)
print("Outcome positive rate (CVD=1):", y.mean().round(3))

"""## **Train/test split (stratified)**"""

# 3. Train/test split (stratified because of imbalance)
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    stratify=y,
    random_state=3002,
)

print("Train size:", X_train.shape[0])
print("Test size:", X_test.shape[0])

"""# **Preprocessing pipeline (numeric imputer + scaler)**"""

# Features we use in the model
feature_cols = [
    "DELTA_PP",
    "V1_AGE",
    "V1_SEX",
    "V1_BMI",
    "V1_SYSBP",
    "V1_DIABP",
    "V1_GLUCOSE",
    "V1_TOTCHOL",
    "V1_CIGPDAY",
]

# Subsets: which ones to log, which to keep linear
log_features = ["V1_GLUCOSE", "V1_TOTCHOL", "V1_CIGPDAY"]
linear_features = [f for f in feature_cols if f not in log_features]

# 1. Transformer for linear numeric features: impute + scale
linear_numeric_transformer = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ]
)

# 2. Transformer for log-transformed features: impute + log1p + scale
log_numeric_transformer = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("log", FunctionTransformer(np.log1p)),
        ("scaler", StandardScaler()),
    ]
)

# 3. ColumnTransformer that applies the right block to each group
preprocess = ColumnTransformer(
    transformers=[
        ("num_linear", linear_numeric_transformer, linear_features),
        ("num_log", log_numeric_transformer, log_features),
    ]
)

"""## **Helper function: unified evaluation**"""

## **Helper function: unified evaluation**

def evaluate_classifier(name, clf, X_train, X_test, y_train, y_test):
    """
    Fit classifier, compute metrics on test set, plot confusion matrix + ROC curve,
    and return a dict with everything needed for later (Streamlit).
    """
    # Fit on training data only
    clf.fit(X_train, y_train)

    # Predictions
    y_pred = clf.predict(X_test)

    # Probabilities / scores
    if hasattr(clf, "predict_proba"):
        y_proba = clf.predict_proba(X_test)[:, 1] # Selects only second column (0/ positive case)
    else:
        # Fallback: use decision_function, then min–max scale to [0,1]
        y_scores = clf.decision_function(X_test)
        y_proba = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)

    # Classification report (dict for saving; string for printing)
    report_dict = classification_report(y_test, y_pred, output_dict=True)
    report_str = classification_report(y_test, y_pred)

    print(f"\n-- {name} --")
    print("Accuracy (test):", round(acc, 3))
    print("ROC AUC (test):", round(auc, 3))
    print("\nClassification report (test):")
    print(report_str)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm,
        display_labels=np.unique(y_test),
    )
    disp.plot(cmap='viridis')
    plt.title(f"Confusion Matrix — {name}")
    plt.tight_layout()
    plt.show()

    # ROC curve
    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    plt.figure(figsize=(6, 5))
    plt.plot([0, 1], [0, 1], "k--")
    plt.plot(fpr, tpr, label=f"{name} (AUC = {auc:.2f})")
    plt.xlabel("False positive rate")
    plt.ylabel("True positive rate (Recall)")
    plt.title(f"ROC Curve — {name}")
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.show()

    # Pack everything in a dict so we can save it
    eval_dict = {
        "name": name,
        "accuracy": float(acc),
        "roc_auc": float(auc),
        "classification_report_dict": report_dict,
        "confusion_matrix": cm,
        "fpr": fpr,
        "tpr": tpr,
        "thresholds": thresholds,
        "y_test": y_test,       # keep as Series
        "y_pred": y_pred,
        "y_proba": y_proba,
    }

    return eval_dict

"""# **ML Models**"""

# Global result storage for comparison table
model_results = []

# Global dict: per-model detailed outputs (for Streamlit app)
all_model_outputs = {}

# Shared stratified CV splitter (reused across all models)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

"""## **Model 1. Dummy Classifier (baseline)**"""

# Model 1 – Baseline DummyClassifier

baseline_pipe = ImbPipeline(
    steps=[
        ("preprocess", preprocess),
        ("model", DummyClassifier(strategy="most_frequent")),
    ]
)

# CV AUC on training set (for comparability with tuned models)
baseline_cv_auc = cross_val_score(
    baseline_pipe,
    X_train,
    y_train,
    cv=cv,
    scoring="roc_auc",
    n_jobs=-1,
)

print("Baseline Dummy – mean CV AUC:", round(baseline_cv_auc.mean(), 3))

# Fit & evaluate on held-out test set
baseline_eval = evaluate_classifier(
    name="Dummy (most frequent)",
    clf=baseline_pipe,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

baseline_eval["model_name"]  = "Dummy (most frequent)"
baseline_eval["cv_best_auc"] = float(baseline_cv_auc.mean())
baseline_eval["best_params"] = {"strategy": "most_frequent"}

all_model_outputs["Dummy (most frequent)"] = baseline_eval

model_results.append({
    "ID": 1,
    "Model": "Dummy (most frequent)",
    "Type": "baseline",
    "Accuracy": baseline_eval["accuracy"],
    "ROC_AUC": baseline_eval["roc_auc"],
    "CV_Best_AUC": baseline_eval["cv_best_auc"],
})

"""## **Model 2. Logistic regression**"""

# Model 2 – Logistic Regression (tuned)

logreg_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("model", LogisticRegression(
        solver="saga", # 0 < l1_ratio < 1 for Elastic-Net
        max_iter=5000, # Times to try for the perfect answer
        class_weight="balanced",
    )),
])

logreg_param_grid = {
    "model__penalty": ["elasticnet"],
    "model__l1_ratio": [0, 0.5, 1],   # 0=Ridge, 1=Lasso, 0.5=mixed
    "model__C": [0.01, 0.1, 1, 10],
}

# Tries all parameter combinations
logreg_grid = GridSearchCV(
    estimator=logreg_pipe,
    param_grid=logreg_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1, # Use all CPU cores
    refit=True,
    verbose=0,
)

logreg_grid.fit(X_train, y_train)

print("Logistic Regression – best CV AUC:", round(logreg_grid.best_score_, 3))
print("Logistic Regression – best params:", logreg_grid.best_params_)

best_logreg = logreg_grid.best_estimator_

logreg_eval = evaluate_classifier(
    name="Logistic Regression (tuned)",
    clf=best_logreg,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

logreg_eval["model_name"]   = "Logistic Regression (tuned)"
logreg_eval["cv_best_auc"]  = float(logreg_grid.best_score_)
logreg_eval["best_params"]  = logreg_grid.best_params_

all_model_outputs["Logistic Regression (tuned)"] = logreg_eval

model_results.append({
    "ID": 2,
    "Model": "Logistic Regression (tuned)",
    "Type": "linear",
    "Accuracy": logreg_eval["accuracy"],
    "ROC_AUC": logreg_eval["roc_auc"],
    "CV_Best_AUC": logreg_eval["cv_best_auc"],
})

"""## **Model 3. Decision Tree**"""

# Model 3 – Decision Tree (tuned)

dt_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("model", DecisionTreeClassifier(
        random_state=42,
        class_weight="balanced"
    )),
])

dt_param_grid = {
    "model__max_depth": [3, 5, 7, 10],
    "model__min_samples_leaf": [1, 2, 5],
    "model__ccp_alpha": [0.0, 0.001, 0.005, 0.01], # Range of values for a grid search to test
}

dt_grid = GridSearchCV(
    estimator=dt_pipe,
    param_grid=dt_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    refit=True,
    verbose=0,
)

dt_grid.fit(X_train, y_train)

print("Decision Tree – best CV AUC:", round(dt_grid.best_score_, 3))
print("Decision Tree – best params:", dt_grid.best_params_)

best_dt = dt_grid.best_estimator_

dt_eval = evaluate_classifier(
    name="Decision Tree (tuned)",
    clf=best_dt,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

dt_eval["model_name"]   = "Decision Tree (tuned)"
dt_eval["cv_best_auc"]  = float(dt_grid.best_score_)
dt_eval["best_params"]  = dt_grid.best_params_

all_model_outputs["Decision Tree (tuned)"] = dt_eval

model_results.append({
    "ID": 3,
    "Model": "Decision Tree (tuned)",
    "Type": "tree",
    "Accuracy": dt_eval["accuracy"],
    "ROC_AUC": dt_eval["roc_auc"],
    "CV_Best_AUC": dt_eval["cv_best_auc"],
})

# Extract the best Decision Tree model from the pipeline
decision_tree_model = best_dt.named_steps['model']

# The ColumnTransformer outputs linear_features first, then log_features
feature_names = linear_features + log_features

# Get class names
class_names = [str(c) for c in sorted(y_train.unique())]

plt.figure(figsize=(20, 15))
plot_tree(
    decision_tree_model,
    feature_names=feature_names,
    class_names=class_names,
    filled=True,
    rounded=True,
    fontsize=8
)
plt.title("Decision Tree Visualization")
plt.show()

"""## **Model 4. Random Forest**"""

# Model 4 – Random Forest (tuned)

rf_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("model", RandomForestClassifier(
        random_state=42,
        class_weight="balanced_subsample",
        n_jobs=-1
    )),
])

rf_param_grid = {
    "model__n_estimators": [200, 400],
    "model__max_depth": [10, 15, None],
    "model__min_samples_split": [2, 5],
    "model__min_samples_leaf": [2, 4],
    "model__max_features": ["sqrt", "log2"],
}

rf_grid.fit(X_train, y_train)

print("Random Forest – best CV AUC:", round(rf_grid.best_score_, 3))
print("Random Forest – best params:", rf_grid.best_params_)

best_rf = rf_grid.best_estimator_

rf_eval = evaluate_classifier(
    name="Random Forest (tuned)",
    clf=best_rf,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

rf_eval["model_name"]   = "Random Forest (tuned)"
rf_eval["cv_best_auc"]  = float(rf_grid.best_score_)
rf_eval["best_params"]  = rf_grid.best_params_

all_model_outputs["Random Forest (tuned)"] = rf_eval

model_results.append({
    "ID": 4,
    "Model": "Random Forest (tuned)",
    "Type": "tree_ensemble",
    "Accuracy": rf_eval["accuracy"],
    "ROC_AUC": rf_eval["roc_auc"],
    "CV_Best_AUC": rf_eval["cv_best_auc"],
})

"""## **Model 5. KNN**"""

# Model 5 – KNN (tuned)

knn_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("smote", SMOTE(random_state=42)),
    ("model", KNeighborsClassifier()),
])

knn_param_grid = {
    "model__n_neighbors": [9, 15, 25],
    "model__weights": ["uniform", "distance"],
    "model__p": [1, 2],
}

knn_grid = GridSearchCV(
    estimator=knn_pipe,
    param_grid=knn_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    refit=True,
    verbose=0,
)

knn_grid.fit(X_train, y_train)

print("KNN – best CV AUC:", round(knn_grid.best_score_, 3))
print("KNN – best params:", knn_grid.best_params_)

best_knn = knn_grid.best_estimator_

knn_eval = evaluate_classifier(
    name="KNN (tuned)",
    clf=best_knn,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

knn_eval["model_name"]   = "KNN (tuned)"
knn_eval["cv_best_auc"]  = float(knn_grid.best_score_)
knn_eval["best_params"]  = knn_grid.best_params_

all_model_outputs["KNN (tuned)"] = knn_eval

model_results.append({
    "ID": 5,
    "Model": "KNN (tuned)",
    "Type": "distance",
    "Accuracy": knn_eval["accuracy"],
    "ROC_AUC": knn_eval["roc_auc"],
    "CV_Best_AUC": knn_eval["cv_best_auc"],
})

"""## **Model 6. Linear SVM**"""

# Model 6 – SVM (RBF, tuned)

svm_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("model", SVC(
        kernel="rbf",
        probability=True,
        class_weight="balanced",
        random_state=42
    )),
])

svm_param_grid = {
    "model__C": [0.1, 1, 10, 100],
    "model__gamma": ["scale", 0.01, 0.1],
    "model__kernel": ["rbf"],
}

svm_grid = GridSearchCV(
    estimator=svm_pipe,
    param_grid=svm_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    refit=True,
    verbose=0,
)

svm_grid.fit(X_train, y_train)

print("SVM (RBF) – best CV AUC:", round(svm_grid.best_score_, 3))
print("SVM (RBF) – best params:", svm_grid.best_params_)

best_svm = svm_grid.best_estimator_

svm_eval = evaluate_classifier(
    name="SVM (RBF, tuned)",
    clf=best_svm,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

svm_eval["model_name"]   = "SVM (RBF, tuned)"
svm_eval["cv_best_auc"]  = float(svm_grid.best_score_)
svm_eval["best_params"]  = svm_grid.best_params_

all_model_outputs["SVM (RBF, tuned)"] = svm_eval

model_results.append({
    "ID": 6,
    "Model": "SVM (RBF, tuned)",
    "Type": "margin",
    "Accuracy": svm_eval["accuracy"],
    "ROC_AUC": svm_eval["roc_auc"],
    "CV_Best_AUC": svm_eval["cv_best_auc"],
})

"""## **Model 7. Gradient Boosting Classifier**"""

# Model 7 – Gradient Boosting (tuned)

gb_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("model", GradientBoostingClassifier(random_state=42)),
])

gb_param_grid = {
    "model__n_estimators": [200, 500],
    "model__learning_rate": [0.01, 0.05],
    "model__max_depth": [3, 4],
    "model__subsample": [0.8, 1.0],
}

gb_grid = GridSearchCV(
    estimator=gb_pipe,
    param_grid=gb_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    refit=True,
    verbose=0,
)

gb_grid.fit(X_train, y_train)

print("Gradient Boosting – best CV AUC:", round(gb_grid.best_score_, 3))
print("Gradient Boosting – best params:", gb_grid.best_params_)

best_gb = gb_grid.best_estimator_

gb_eval = evaluate_classifier(
    name="Gradient Boosting (tuned)",
    clf=best_gb,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

gb_eval["model_name"]   = "Gradient Boosting (tuned)"
gb_eval["cv_best_auc"]  = float(gb_grid.best_score_)
gb_eval["best_params"]  = gb_grid.best_params_

all_model_outputs["Gradient Boosting (tuned)"] = gb_eval

model_results.append({
    "ID": 7,
    "Model": "Gradient Boosting (tuned)",
    "Type": "tree_ensemble",
    "Accuracy": gb_eval["accuracy"],
    "ROC_AUC": gb_eval["roc_auc"],
    "CV_Best_AUC": gb_eval["cv_best_auc"],
})

"""## **Model 8. Neural Network (Multi-layer perceptron)**"""

# Model 8 – MLP (sklearn NN, tuned)

mlp_pipe = ImbPipeline(steps=[
    ("preprocess", preprocess),
    ("smote", SMOTE(random_state=42)),
    ("model", MLPClassifier(
        early_stopping=True,
        max_iter=1000,
        random_state=42,
    )),
])

mlp_param_grid = {
    "model__hidden_layer_sizes": [(64, 32), (100,)],
    "model__alpha": [0.001, 0.01, 0.1],
    "model__learning_rate_init": [0.001, 0.005],
}

mlp_grid = GridSearchCV(
    estimator=mlp_pipe,
    param_grid=mlp_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=-1,
    refit=True,
    verbose=0,
)

mlp_grid.fit(X_train, y_train)

print("MLP – best CV AUC:", round(mlp_grid.best_score_, 3))
print("MLP – best params:", mlp_grid.best_params_)

best_mlp = mlp_grid.best_estimator_

mlp_eval = evaluate_classifier(
    name="Neural Network (MLP, tuned)",
    clf=best_mlp,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

mlp_eval["model_name"]   = "Neural Network (MLP, tuned)"
mlp_eval["cv_best_auc"]  = float(mlp_grid.best_score_)
mlp_eval["best_params"]  = mlp_grid.best_params_

all_model_outputs["Neural Network (MLP, tuned)"] = mlp_eval

model_results.append({
    "ID": 8,
    "Model": "Neural Network (MLP, tuned)",
    "Type": "neural_net",
    "Accuracy": mlp_eval["accuracy"],
    "ROC_AUC": mlp_eval["roc_auc"],
    "CV_Best_AUC": mlp_eval["cv_best_auc"],
})

"""## **Model 9. TensorFlow NN**

### **Keras wrapper for TensorFlow NN**
"""

# Keras wrapper for TensorFlow NN

class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):
    """
    A scikit-learn compatible wrapper for Keras models.

    build_fn must be a function with signature:
        build_fn(input_dim, n_classes, learning_rate, hidden_units1,
                 hidden_units2, dropout_rate) -> compiled keras.Model
    """

    def __init__(
        self,
        build_fn,
        epochs=10,
        batch_size=None,
        verbose=0,
        # Model-building hyperparameters (explicit for sklearn)
        input_dim=None,
        n_classes=2,
        learning_rate=0.001,
        hidden_units1=64,
        hidden_units2=32,
        dropout_rate=0.2,
    ):
        self.build_fn = build_fn
        self.epochs = epochs
        self.batch_size = batch_size
        self.verbose = verbose

        # these must be attributes so GridSearchCV can see/clone them
        self.input_dim = input_dim
        self.n_classes = n_classes
        self.learning_rate = learning_rate
        self.hidden_units1 = hidden_units1
        self.hidden_units2 = hidden_units2
        self.dropout_rate = dropout_rate

        self._model = None
        self.classes_ = None   # will be set in fit

    def _build_model(self):
        if self.input_dim is None:
            raise ValueError("input_dim must be set before fitting the model.")

        model = self.build_fn(
            input_dim=self.input_dim,
            n_classes=self.n_classes,
            learning_rate=self.learning_rate,
            hidden_units1=self.hidden_units1,
            hidden_units2=self.hidden_units2,
            dropout_rate=self.dropout_rate,
        )
        if not isinstance(model, keras.Model):
            raise ValueError("build_fn must return a compiled keras.Model")
        return model

    def fit(self, X, y, **fit_params):
        X = np.asarray(X, dtype="float32")
        y = np.asarray(y)

        # store class labels in sklearn-style attribute
        self.classes_ = np.unique(y)

        # compute balanced class weights
        class_weights_array = compute_class_weight(
            class_weight="balanced",
            classes=self.classes_,
            y=y,
        )
        class_weight = dict(zip(self.classes_, class_weights_array))

        # build (or rebuild) model
        self._model = self._build_model()

        self._model.fit(
            X,
            y,
            epochs=self.epochs,
            batch_size=self.batch_size,
            verbose=self.verbose,
            class_weight=class_weight,   # 👈 THIS IS THE KEY LINE
            **fit_params,
        )
        return self

    def predict_proba(self, X):
        X = np.asarray(X, dtype="float32")
        if self._model is None:
            raise RuntimeError("You must call fit before predict_proba.")
        proba = self._model.predict(X, verbose=0)

        # Ensure 2D output (n_samples, n_classes)
        if proba.ndim == 1:
            proba = np.stack([1 - proba, proba], axis=1)
        elif proba.shape[1] == 1:
            proba_pos = proba[:, 0]
            proba = np.stack([1 - proba_pos, proba_pos], axis=1)

        return proba

    def predict(self, X):
        proba = self.predict_proba(X)
        return np.argmax(proba, axis=1)

    def score(self, X, y):
        from sklearn.metrics import accuracy_score

        y_pred = self.predict(X)
        return accuracy_score(y, y_pred)


def build_tf_model(
    input_dim,
    n_classes=2,
    learning_rate=0.001,
    hidden_units1=64,
    hidden_units2=32,
    dropout_rate=0.2,
):
    """
    Simple feedforward network for binary classification.
    input_dim: number of input features (after preprocessing).
    n_classes: 2 for binary CVD (output is sigmoid).
    """
    model = keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(hidden_units1, activation="relu"),
        keras.layers.Dense(hidden_units2, activation="relu"),
        keras.layers.Dropout(dropout_rate),
        keras.layers.Dense(1, activation="sigmoid"),  # binary outcome
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss="binary_crossentropy",
        metrics=[keras.metrics.AUC(name="AUC")],
    )
    return model

"""### **Model 9 - TensorFlow NN**"""

# Model 9 – TensorFlow NN (tuned)

# define input_dim
input_dim = len(feature_cols)

tf_nn_pipe = ImbPipeline(
    steps=[
        ("preprocess", preprocess),
        ("model", KerasClassifierWrapper(
            build_fn=build_tf_model,
            epochs=40,
            batch_size=32,
            verbose=0,
            input_dim=input_dim,
            n_classes=2,
            learning_rate=0.001,
            hidden_units1=64,
            hidden_units2=32,
            dropout_rate=0.2,
        )),
    ]
)

tf_param_grid = {
    "model__epochs": [30, 50],
    "model__batch_size": [32, 64],
}

tf_grid = GridSearchCV(
    estimator=tf_nn_pipe,
    param_grid=tf_param_grid,
    scoring="roc_auc",
    cv=cv,
    n_jobs=1,
    refit=True,
    verbose=0,
)

tf_grid.fit(X_train, y_train)

print("TensorFlow NN – best CV AUC:", round(tf_grid.best_score_, 3))
print("TensorFlow NN – best params:", tf_grid.best_params_)

best_tf_nn = tf_grid.best_estimator_

tf_eval = evaluate_classifier(
    name="Neural Network (TensorFlow, tuned)",
    clf=best_tf_nn,
    X_train=X_train,
    X_test=X_test,
    y_train=y_train,
    y_test=y_test,
)

tf_eval["model_name"]   = "Neural Network (TensorFlow, tuned)"
tf_eval["cv_best_auc"]  = float(tf_grid.best_score_)
tf_eval["best_params"]  = tf_grid.best_params_

all_model_outputs["Neural Network (TensorFlow, tuned)"] = tf_eval

model_results.append({
    "ID": 9,
    "Model": "Neural Network (TensorFlow, tuned)",
    "Type": "neural_net",
    "Accuracy": tf_eval["accuracy"],
    "ROC_AUC": tf_eval["roc_auc"],
    "CV_Best_AUC": tf_eval["cv_best_auc"],
})

"""# **Model results**"""

# Build comparison table from all stored model results
results_df = pd.DataFrame(model_results)

# Sort by ROC_AUC (best model at the top)
results_sorted = results_df.sort_values("ROC_AUC", ascending=False).reset_index(drop=True)

print("Model comparison (sorted by ROC_AUC):")
display(results_sorted)

# Results already in `results_df`

# 1) Drop exact duplicates (same ID + Model + metrics)
results_df_clean = results_df.drop_duplicates(
    subset=["ID", "Model", "Accuracy", "ROC_AUC"]
).copy()

# 2) Sort by ROC AUC (descending)
plot_df = results_df_clean.sort_values("ROC_AUC", ascending=False).reset_index(drop=True)

plot_df

"""## **ROC AUC ranked by model**"""

plt.figure(figsize=(8, 5))
sns.barplot(
    data=results_sorted,
    x="Accuracy",
    y="Model",
    palette="viridis"
)
plt.title("Model Comparison – Accuracy (Test Set)")
plt.xlabel("Accuracy")
plt.ylabel("")
plt.xlim(0.5, 1.0)
plt.tight_layout()
plt.show()

"""## **Visual: AUC ranking scatter: Accuracy vs. ROC AUC**"""

plt.figure(figsize=(6, 6))

sns.scatterplot(
    data=plot_df,
    x="ROC_AUC",
    y="Accuracy",
    hue="Type",
    style="Type",
    s=90,
    palette="viridis",
)

for _, row in plot_df.iterrows():
    plt.text(
        x=row["ROC_AUC"] + 0.002,
        y=row["Accuracy"] + 0.002,
        s=str(row["ID"]),      # label by ID to keep it compact
        fontsize=8,
    )

plt.title("Accuracy vs ROC AUC per Model")
plt.xlabel("ROC AUC")
plt.ylabel("Accuracy")
plt.xlim(0.45, 0.8)
plt.ylim(0.55, 0.8)
plt.axhline(0.5, color="grey", linestyle="--", linewidth=0.8)
plt.axvline(0.5, color="grey", linestyle="--", linewidth=0.8)
plt.tight_layout()
plt.show()

# ===============================
# Save objects for Streamlit app
# ===============================
import joblib

# 1) Final analytic dataset (for any extra analysis / checks in app if needed)
analytic.to_csv("analytic_dataset.csv", index=False)
print("Saved analytic dataset -> analytic_dataset.csv")

# 2) Model comparison table
results_sorted.to_csv("model_results.csv", index=False)
print("Saved model summary table -> model_results.csv")

# 3) Detailed per-model outputs (metrics, ROC, cm, etc.)
joblib.dump(all_model_outputs, "all_model_outputs.pkl")
print("Saved detailed model outputs -> all_model_outputs.pkl")

# ------------------------------------------------------------
# Download all output files as a single ZIP archive
# ------------------------------------------------------------
import os
import zipfile
from google.colab import files

# List every file you want included in the ZIP
files_to_zip = [
    "analytic_dataset.csv",
    "model_results.csv",
    "all_model_outputs.pkl",
]

zip_filename = "framingham_model_outputs.zip"

# Create ZIP
with zipfile.ZipFile(zip_filename, "w") as z:
    for f in files_to_zip:
        if os.path.isfile(f):
            z.write(f)
        else:
            print(f"⚠️ Warning: {f} not found, skipping.")

# Download ZIP
files.download(zip_filename)

print("\n✅ ZIP file created and download started: framingham_model_outputs.zip")